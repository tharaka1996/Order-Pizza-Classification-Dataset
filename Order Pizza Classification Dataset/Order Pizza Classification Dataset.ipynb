{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ff7ce6",
   "metadata": {},
   "source": [
    "# Order Pizza Classification Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21d745",
   "metadata": {},
   "source": [
    "1. Import the Dataset\n",
    "2. Text Preprocessing (Tokenization, Stopwords, Stemming, Lemmatization, NLTK)\n",
    "3. Text convert into vectors (Bag of words, TF-IDF)\n",
    "4. Train Test Split\n",
    "5. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701e6b9",
   "metadata": {},
   "source": [
    "# Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5708a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ef8761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Dataset\n",
    "df = pd.read_csv(\"Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34e288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intentName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dont want the order anymore</td>\n",
       "      <td>CancelOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dont make my order anymore</td>\n",
       "      <td>CancelOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancel the order</td>\n",
       "      <td>CancelOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancel that order</td>\n",
       "      <td>CancelOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i would like to order three hawaiian pizzas wi...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i would like to order two small chicken pizzas...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i would like two cheese pizzas with extra anch...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i would like two cheese pizzas with extra anch...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i would like two extra large pizzas with ham</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pepperoni pizzas without olives but extra sauce</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   intentName\n",
       "0                        dont want the order anymore  CancelOrder\n",
       "1                         dont make my order anymore  CancelOrder\n",
       "2                                   cancel the order  CancelOrder\n",
       "3                                  cancel that order  CancelOrder\n",
       "4  i would like to order three hawaiian pizzas wi...  ModifyOrder\n",
       "5  i would like to order two small chicken pizzas...  ModifyOrder\n",
       "6  i would like two cheese pizzas with extra anch...  ModifyOrder\n",
       "7  i would like two cheese pizzas with extra anch...  ModifyOrder\n",
       "8       i would like two extra large pizzas with ham  ModifyOrder\n",
       "9    pepperoni pizzas without olives but extra sauce  ModifyOrder"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ea49ef0",
   "metadata": {},
   "source": [
    "In here, text is the entire description of the text that is present in the dataset. intentName is basically output feature can be CancelOrder, ModifyOrder ..etc.\n",
    "1.text - Input feature\n",
    "2.intentName - dependent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20535780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the DataFrame rows\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222d08ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intentName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>what is my name</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>i would like three pepperoni pizzas hold the s...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>looks right</td>\n",
       "      <td>Confirmation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>let me get two small chicken pizzas without ja...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>order one pizza</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>i would like a large vegetarian pizza half oni...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>correct</td>\n",
       "      <td>Confirmation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>i want one extra large pepperoni pizza with ex...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>yes</td>\n",
       "      <td>Confirmation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>order one mandarin pizza thin crust with extra...</td>\n",
       "      <td>ModifyOrder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text    intentName\n",
       "67                                    what is my name          None\n",
       "23  i would like three pepperoni pizzas hold the s...   ModifyOrder\n",
       "14                                        looks right  Confirmation\n",
       "11  let me get two small chicken pizzas without ja...   ModifyOrder\n",
       "40                                    order one pizza   ModifyOrder\n",
       "58  i would like a large vegetarian pizza half oni...   ModifyOrder\n",
       "51                                            correct  Confirmation\n",
       "80  i want one extra large pepperoni pizza with ex...   ModifyOrder\n",
       "48                                                yes  Confirmation\n",
       "39  order one mandarin pizza thin crust with extra...   ModifyOrder"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06db4ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'order a chicken pizza'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].loc[46]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fe780",
   "metadata": {},
   "source": [
    "# Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f812086a",
   "metadata": {},
   "source": [
    "First thing first over here for the data cleaning process, I'm going to import three imporatant libraries that called as a regular expression, nltk and stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1830198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TharakaG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6cda957",
   "metadata": {},
   "source": [
    "Then nltk.corpus i'm going to import stop words and then i'm going to import porter stemmer. This porter stemmer is used for stemming purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb66236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20faf889",
   "metadata": {},
   "source": [
    "In here,i have for i in range of zero comma lenghth of texts and traversing through all texts and this first word remove all special characters other than small a to z and capital A to Z. Then do the lowering of the sentences so that duplicate words will not be present over there. Then do splitting of this entire words and for each every word traverse it apply to stop words and then apply stemming.\n",
    "Finally join review and put that back in corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf737c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z0-9]', ' ', df['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')] \n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "827ad151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dont want order anymor',\n",
       " 'dont make order anymor',\n",
       " 'cancel order',\n",
       " 'cancel order',\n",
       " 'would like order three hawaiian pizza without ham add oliv',\n",
       " 'would like order two small chicken pizza pepperoni',\n",
       " 'would like two chees pizza extra anchovi small chicken pizza without ham pineappl',\n",
       " 'would like two chees pizza extra anchovi small chicken pizza without ham pineappl anchovi',\n",
       " 'would like two extra larg pizza ham',\n",
       " 'pepperoni pizza without oliv extra sauc',\n",
       " 'id like order larg pizza extra pepperoni extra chicken extra chees',\n",
       " 'let get two small chicken pizza without jalapeno add ham',\n",
       " 'want two extra larg beef suprem pizza without pepperoni oliv',\n",
       " 'look good',\n",
       " 'look right',\n",
       " 'pretti much',\n",
       " 'right',\n",
       " 'confirm',\n",
       " 'confirm',\n",
       " 'awesom',\n",
       " 'hello',\n",
       " 'would like medium pizza extra mushroom light sausag remov chees',\n",
       " 'would like pepperoni pizza extra chees side ranch',\n",
       " 'would like three pepperoni pizza hold sauc',\n",
       " 'would like order four chees pizza extra chees chicken pizza without chicken',\n",
       " 'would like order ham pizza doubl chees',\n",
       " 'would like order larg pizza italian sausag ham extra oliv',\n",
       " 'want eat one extra larg pepperoni pizza extra sausag oliv side garlic bread okay',\n",
       " 'want order chicken pizza',\n",
       " 'would like one larg chicken pizza extra mushroom half',\n",
       " 'weather today',\n",
       " 'penguin ocean',\n",
       " 'rate product 4 5 star',\n",
       " 'bark dog annoy',\n",
       " 'order small pizza',\n",
       " 'order small pizza',\n",
       " 'order larg pepperoni pizza',\n",
       " 'want two larg pepperoni pizza thin crust',\n",
       " 'want two small seafood pizza extra chees',\n",
       " 'order one mandarin pizza thin crust extra pineappl anchovi onion without pepper fri side',\n",
       " 'order one pizza',\n",
       " 'pleas order twelv chelsea pizza want ham',\n",
       " 'pleas order two pan crust small pepperoni pizza beef three medium chees pizza italian sausag',\n",
       " 'request seven larg honolulu hawaiian pizza bacon salami add chicken wing',\n",
       " 'one medium pepperoni one side macaroni chees pleas',\n",
       " 'one medium pepperoni replac anchovi oliv',\n",
       " 'order chicken pizza',\n",
       " 'great',\n",
       " 'ye',\n",
       " 'ye order',\n",
       " 'go head',\n",
       " 'correct',\n",
       " 'order four four chees pizza extra chees chicken pizza without chicken extra mushroom half side bread',\n",
       " 'order one chicken pizza',\n",
       " 'would like order medium thin pepperoni pizza extra italian sausag half',\n",
       " 'would like order pepperoni pizza extra oliv half side bread',\n",
       " 'want two medium chicken pizza anchovi',\n",
       " 'want two pepperoni pizza',\n",
       " 'would like larg vegetarian pizza half onion half pepper',\n",
       " 'want order hawaiian pizza',\n",
       " 'want order larg clam pizza extra white sauc side order garlic knot go',\n",
       " 'want order larg four chees pizza extra chees chicken pizza without chicken',\n",
       " 'want order medium chees pizza root beer',\n",
       " 'want order pizza oliv one half green pepper half',\n",
       " 'want order iceland pizza',\n",
       " '',\n",
       " 'time',\n",
       " 'name',\n",
       " 'want one larg chicken pizza extra pepper hold anchovi',\n",
       " 'want one larg chicken ranch pizza extra muhsroom without ham garlic knot side',\n",
       " 'want one larg pepperoni pizza extra anchovi pleas',\n",
       " 'want one small hawaiian pizza extra corn pineappl two medium plain pizza without pepper replac mushroom anchovi extra larg happi pizza half oliv half pepper',\n",
       " 'want six cheesi pizza',\n",
       " 'want three chees pizza',\n",
       " 'want three cuban pizza bacon mushroom fri side',\n",
       " 'want three larg thin crust mexican pizza without anchovi pineappl extra larg pepperoni pizza extra chees oliv mushroom half',\n",
       " 'want four hawaiian pizza want jalapeno',\n",
       " 'want four pepperoni pizza chicken',\n",
       " 'want one cheesi pizza larg italian sausag',\n",
       " 'want one extra larg pepperoni pizza anchovi ham without oliv one larg chicken pizza hold pepper side order garlic knot',\n",
       " 'want one extra larg pepperoni pizza extra ham remov oliv chicken two medium stuf crust super suprem pizza anchovi chees',\n",
       " 'want one larg pizza extra chees']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c1649",
   "metadata": {},
   "source": [
    "# Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c56bc9ac",
   "metadata": {},
   "source": [
    "Here applying count vectorizer this is just for the the bag of words model. In BOW going to take all corpus that is present over here after cleaning it. Count Vectorizer is basically used to create the bag of words over there. max_features = 2500, we can select different different values. It is basically take the maximum top maximum 2500 features if we want. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f304947a",
   "metadata": {},
   "source": [
    "Vectorization is a process of converting the text data into a machine-readable form. This is using CountVectorizer model and binary equal to True basically says that if a word is present two times in a sentence anyhow if it is greater than one the value in the bag of words will be only one itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b060b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=2500, binary = True, ngram_range = (2,2))\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988bf58c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c21075c",
   "metadata": {},
   "source": [
    "In here using the get_dummies to get y values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb7e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(df['intentName'])\n",
    "y=y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37242e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d90b3a",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94cfe127",
   "metadata": {},
   "source": [
    "Train Test Split, there is imported library called model selection and taken x and y. test_size taken 0.20 and random_state equal to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "431a06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f905038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       dtype=uint8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a3135ae",
   "metadata": {},
   "source": [
    "In here, I use Multinomial naive bayes machine learning algorithms to this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70e80854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b7958",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "393adb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c2e140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f4b13ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75f9d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79        13\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.37      0.42      0.39        17\n",
      "weighted avg       0.56      0.65      0.60        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7571bb54",
   "metadata": {},
   "source": [
    "# Creating the TFIDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1963305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(max_features=2500, ngram_range = (1,2))\n",
    "X = tv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d851cae",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6326ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4cd181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679f083",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cded0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=spam_detect_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a800ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "score=accuracy_score(y_test,y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99664b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88        17\n",
      "   macro avg       0.50      0.44      0.47        17\n",
      "weighted avg       1.00      0.88      0.94        17\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\New folder (3)\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\New folder (3)\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\New folder (3)\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
